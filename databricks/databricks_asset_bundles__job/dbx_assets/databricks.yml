# Databricks Asset Bundle configuration, more info here: https://docs.databricks.com/en/dev-tools/bundles/settings.html
bundle:
  name: "pipelines"

include:
  - resources/*.yml
  - resources/*/*.yml

variables:
  cluster_id:
    description: The ID of an existing cluster.
    default: 1234-567890-abcde123
  sql_warehouse_id:
    description: The ID of the sql warehouse to run dbt code.
    default: 1a12345a1234a12a
  git_branch_name:
    description: The name of the git branch to reference in the pipeline
    default: dev

targets:
  # The 'dev' target, for development purposes. This target is the default.
  dev:
    mode: development
    default: true
    workspace:
      host: https://adb-123456789101112.1.azuredatabricks.net
    run_as:
      # This runs as etlservice_dev (service principal) in dev.
      service_principal_name: 1a234567-a12b-1ab2-a123-1a234bc56789
    permissions:
      - group_name: dataplatformdev-data_engineer
        level: CAN_MANAGE
      - group_name: dataplatformdev-super_analyst
        level: CAN_RUN
    variables:
      cluster_id: 1234-567890-abcde123
      git_branch_name: dev
      sql_warehouse_id: 1a12345a1234a12a

  # The 'prod' target, used for production deployment.
  prod:
    mode: production
    workspace:
      host: https://adb-123456789101112.1.azuredatabricks.net
      # We always use /Users/edward@data-cubed.co.uk for all resources to make sure we only have a single copy.
      root_path: /Users/edward@data-cubed.co.uk/.bundle/${bundle.name}/${bundle.target}
    run_as:
      # This runs as etlservice_prod (service principal) in production.
      service_principal_name: 46e5168c-8f2c-4335-a5ce-ac0fa8aadfea
    permissions:
      - group_name: dataplatformprod-data_engineer
        level: CAN_MANAGE
      - group_name: dataplatformprod-super_analyst
        level: CAN_RUN
    variables:
      cluster_id: 1234-567890-abcde123
      git_branch_name: main
      sql_warehouse_id: 1a12345a1234a12a
